{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "from scipy.signal import find_peaks\n",
    "from collections import Counter\n",
    "from carmodel_calibration.data_integration.helper import (\n",
    "    get_lane, get_angle, get_difference)\n",
    "from carmodel_calibration.helpers import _get_starting_time, _get_vehicle_meta_data\n",
    "from carmodel_calibration.data_integration.data_set import DataSet\n",
    "filename = DataSet(Path(os.environ[\"DATA_DIR\"])).get_filename_by_id(1)\n",
    "data, meta_data, lane_data = DataSet.read_file(Path(filename))\n",
    "data.to_csv(\".tmp/data.csv\", index=False)\n",
    "meta_data.to_csv(\".tmp/meta_data.csv\", index=False)\n",
    "lane_data.to_csv(\".tmp/lane_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def car_goes_straight(lane_data, data_chunk):\n",
    "    \"\"\"calculate distance (int) between cars from dataframe chunks\"\"\"\n",
    "    if \"lane\" not in data_chunk.columns:\n",
    "        data_chunk[\"lane\"] = get_lane(data_chunk[\"xCenter\"],\n",
    "                                      data_chunk[\"yCenter\"],\n",
    "                                      lane_data, True)\n",
    "    lane = data_chunk[\"lane\"].values\n",
    "    # TODO: instead of counter, integrate the lane over the traveled distance\n",
    "    # for more accurate lane identification\n",
    "    lane_counts = sorted(list(Counter(lane).values()), reverse=True)\n",
    "    lane_mean = np.rint(np.mean(lane))\n",
    "    lane_xy = (lane_data[lane_data[\"trackId\"]==lane_mean]\n",
    "               [[\"xCenter\", \"yCenter\"]].values[::10])\n",
    "    # xy_center = data_chunk[[\"xCenter\", \"yCenter\"]].values[:-100:10]\n",
    "    xy_center = data_chunk[[\"xCenter\", \"yCenter\"]].values[::10]\n",
    "    distance =  get_difference(xy_center[:,0], xy_center[:,1],\n",
    "                              lane_xy[:,0], lane_xy[:,1])\n",
    "    if any(distance > 15):\n",
    "        return False\n",
    "    if np.mean(distance) > 7:\n",
    "        return False\n",
    "    if len(lane_counts) < 2:\n",
    "        return True\n",
    "    # return True\n",
    "    return lane_counts[1] / lane_counts[0] < 0.1\n",
    "def angle_diff(traj_a, traj_b):\n",
    "    \"\"\"both trajectories in degree\"\"\"\n",
    "    diff = traj_a - traj_b\n",
    "    return (diff + 180) % 360 - 180\n",
    "\n",
    "def euclidian_distance(pos1, pos2):\n",
    "    \"\"\"calculate the euclidian distance between 2points in n-dim space\"\"\"\n",
    "    return np.sum(np.square(pos1-pos2), axis=1) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: <object object at 0x00000266036CE980>\n"
     ]
    }
   ],
   "source": [
    "def following_cars(data: pd.DataFrame, lane_data: pd.DataFrame,\n",
    "                   meta_data: pd.DataFrame, use_xy=False):\n",
    "    \"\"\"\n",
    "    generator that gets ids of cars that are classified as following each other\n",
    "    :yield:         yields tuple of IDs of 2 cars , that are following each\n",
    "                    other, and their distance as np array\n",
    "    \"\"\"\n",
    "    dist_threshold = 100\n",
    "    speed_threshold = 1.5\n",
    "    min_gap_treshold = 0.1\n",
    "    abscissa = \"xCenter\" if use_xy else \"lon\"\n",
    "    ordinate = \"yCenter\" if use_xy else \"lat\"\n",
    "    unique_tracks = data[\"trackId\"].unique()\n",
    "    crossing_times = np.zeros((int(\n",
    "        unique_tracks.shape[0])))\n",
    "    for track_id, track_name in enumerate(unique_tracks):\n",
    "        crossing_time = data[data[\"trackId\"]==track_name][\"intersectionCrossing\"]\n",
    "        crossing_time = crossing_time.values[0]\n",
    "        crossing_times[track_id] = crossing_time\n",
    "    for leader_id, leader in enumerate(unique_tracks):\n",
    "        data_chunk = data[data[\"trackId\"]==leader]\n",
    "        leader_meta, _ = _get_vehicle_meta_data(\n",
    "            meta_data, (leader, None, meta_data.iloc[0][\"recordingId\"]))\n",
    "        if leader_meta[\"class\"] not in [\"Car\", \"Van\"]:\n",
    "            continue\n",
    "        if leader in [108, 112, 92]:\n",
    "            print(\"debug\")\n",
    "        starting_time_l = _get_starting_time(data_chunk)\n",
    "        if \"lane\" not in data_chunk.columns:\n",
    "            data_chunk[\"lane\"] = get_lane(data_chunk[abscissa],\n",
    "                                          data_chunk[ordinate],\n",
    "                                          lane_data)\n",
    "        # check lane\n",
    "        if not car_goes_straight(lane_data, data_chunk):\n",
    "            continue\n",
    "        if crossing_times[leader_id] == 0:\n",
    "            continue\n",
    "        if not any(data_chunk[\"speed\"] < speed_threshold):\n",
    "            continue\n",
    "        if crossing_times[leader_id] == 0:\n",
    "            continue\n",
    "        # cars that are in the same timeframe, with the same heading\n",
    "        # and position\n",
    "        lane = np.rint(np.mean(data_chunk[\"lane\"].values))\n",
    "        # do not consider zero values in mean for heading\n",
    "        heading = np.true_divide(data_chunk[\"heading\"].values.sum(0),\n",
    "                                 (data_chunk[\"heading\"].values!=0).sum(0))\n",
    "        leader_frames = data_chunk[\"frame\"].values\n",
    "        next_cars = np.argsort(\n",
    "            np.abs(crossing_times - crossing_times[leader_id]))\n",
    "        for follower_id in next_cars:\n",
    "            follower = unique_tracks[follower_id]\n",
    "            if follower == leader:\n",
    "                continue\n",
    "            next_chunk = data[data[\"trackId\"] == follower]\n",
    "            leader_meta, follower_meta = _get_vehicle_meta_data(\n",
    "                meta_data, (leader, follower, 1))\n",
    "            if len(next_chunk) == 0:\n",
    "                continue\n",
    "            if follower_meta[\"class\"] not in [\"Car\", \"Van\"]:\n",
    "                continue\n",
    "            overlapping_frames = np.intersect1d(\n",
    "                next_chunk[\"frame\"].values, leader_frames)\n",
    "            if overlapping_frames.shape[0] == 0:\n",
    "                continue\n",
    "            start = (\n",
    "                next_chunk[next_chunk[\"frame\"]==overlapping_frames[0]\n",
    "                           ][\"time\"].values[0])\n",
    "            stop = (\n",
    "                next_chunk[next_chunk[\"frame\"]==overlapping_frames[-1]\n",
    "                           ][\"time\"].values[0])\n",
    "            overlapping_time = stop - start\n",
    "            # check that follower follows at least 5 seconds\n",
    "            if overlapping_time < 5:\n",
    "                continue\n",
    "            if not car_goes_straight(lane_data, next_chunk):\n",
    "                # print(\"because of not straight\")\n",
    "                continue\n",
    "            # check lane\n",
    "            if \"lane\" not in next_chunk.columns:\n",
    "                next_chunk[\"lane\"] = get_lane(next_chunk[abscissa],\n",
    "                                              next_chunk[ordinate],\n",
    "                                              lane_data)\n",
    "            follower_lane = np.rint(np.mean(next_chunk[\"lane\"].values))\n",
    "            if follower_lane != lane:\n",
    "                continue\n",
    "            # check heading\n",
    "            next_heading = np.true_divide(next_chunk[\"heading\"].values.sum(0),\n",
    "                                 (next_chunk[\"heading\"].values!=0).sum(0))\n",
    "            if angle_diff(heading, next_heading) > 20:\n",
    "                continue\n",
    "            # get position in meters\n",
    "            overlap_leader = data_chunk[\n",
    "            data_chunk[\"frame\"].isin(overlapping_frames)]\n",
    "            pos_leader = overlap_leader[[\"xCenter\",\"yCenter\"]].values\n",
    "            overlap_follower = next_chunk[\n",
    "                next_chunk[\"frame\"].isin(overlapping_frames)]\n",
    "            pos_follower = overlap_follower[[\"xCenter\", \"yCenter\"]].values\n",
    "            # check distance\n",
    "            distance = euclidian_distance(pos_leader, pos_follower)\n",
    "            if any(distance > dist_threshold):\n",
    "                continue\n",
    "            # get position in lat lon\n",
    "            overlap_leader = data_chunk[\n",
    "            data_chunk[\"frame\"].isin(overlapping_frames)]\n",
    "            pos_leader = overlap_leader[[abscissa,ordinate]].values\n",
    "            overlap_follower = next_chunk[\n",
    "                next_chunk[\"frame\"].isin(overlapping_frames)]\n",
    "            pos_follower = overlap_follower[[abscissa, ordinate]].values\n",
    "            # check that follower is behind leader\n",
    "            attack_vector = pos_leader - pos_follower\n",
    "            attack_vector_angle = get_angle(attack_vector)\n",
    "            condition = (\n",
    "                (np.abs(angle_diff(attack_vector_angle, heading)) > 50)\n",
    "                & (overlap_leader[\"speed\"].values > 1)\n",
    "                & (overlap_follower[\"speed\"].values > 1)\n",
    "            )\n",
    "            if np.any(condition):\n",
    "                continue\n",
    "            time_ss, follower_distance_ss = (\n",
    "                next_chunk.iloc[next_chunk[\"speed\"].argmin()]\n",
    "                [[\"time\",\"distanceIntersectionCrossing\"]])\n",
    "            leader_distance_ss = (\n",
    "                data_chunk.iloc[(data_chunk[\"time\"] - time_ss).abs().argmin()]\n",
    "                [\"distanceIntersectionCrossing\"])\n",
    "            condition = (\n",
    "                (data[\"lane\"]==lane)\n",
    "                & ((data[\"distanceIntersectionCrossing\"]\n",
    "                   < leader_distance_ss) & (np.isclose(data[\"time\"],\n",
    "                                                       time_ss,\n",
    "                                                       atol=0.5)))\n",
    "                & ((data[\"distanceIntersectionCrossing\"]\n",
    "                   > follower_distance_ss) & (np.isclose(data[\"time\"],\n",
    "                                                         time_ss,\n",
    "                                                         atol=0.5)))\n",
    "                & (~data[\"trackId\"].isin([leader, follower_id]))\n",
    "            )\n",
    "            pos_follower = next_chunk[next_chunk[\"time\"]==starting_time_l]\n",
    "            pos_leader = data_chunk[data_chunk[\"time\"]==starting_time_l]\n",
    "            if len(pos_follower) > 0:\n",
    "                pos_follower_xy = pos_follower[[\"xCenter\", \"yCenter\"]].values[0]\n",
    "                pos_leader_xy = pos_leader[[\"xCenter\", \"yCenter\"]].values[0]\n",
    "                len_l, len_f = leader_meta[\"length\"], follower_meta[\"length\"]\n",
    "                min_gap = (np.sqrt(np.sum(np.square(pos_leader_xy-pos_follower_xy)))\n",
    "                        - (len_l + len_f) / 2)\n",
    "                if min_gap < min_gap_treshold:\n",
    "                    break\n",
    "            if np.isclose(crossing_times[follower_id], 0):\n",
    "                break\n",
    "            if not next_chunk[\"speed\"].min() < speed_threshold:\n",
    "                break\n",
    "            if np.any(condition):\n",
    "                break\n",
    "            yield (leader, follower)\n",
    "            break\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib auto\n",
    "# straight_cars = []\n",
    "# turning_cars = []\n",
    "# for track_id, chunk in data.groupby(by=[\"trackId\"]):\n",
    "#     if track_id == 88:\n",
    "#         print(\"debug\")\n",
    "#     if car_goes_straight(lane_data, chunk):\n",
    "#         straight_cars.append(track_id)\n",
    "#     else:\n",
    "#         turning_cars.append(track_id)\n",
    "# print(len(straight_cars))\n",
    "# print(len(turning_cars))\n",
    "# pairs = []\n",
    "# for leader, follower in following_cars(data, lane_data, meta_data, True):\n",
    "#     pairs.append((leader, follower))\n",
    "# print(len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_following_cars2(data: pd.DataFrame, lane_data: pd.DataFrame,\n",
    "                   meta_data: pd.DataFrame, use_xy=False, lanes: list = None,\n",
    "                   classes : list = [\"Car\", \"Van\"]):\n",
    "    if not lanes:\n",
    "        lanes = np.unique(lane_data[\"trackId\"])\n",
    "    times = np.sort(data[\"time\"].unique())[:2]\n",
    "    fps = np.rint(1 / (times[1] - times[0])).astype(int)\n",
    "    track_ids = []\n",
    "    trajectories = data.copy()\n",
    "    for track_id, chunk in data.groupby(by=[\"trackId\"]):\n",
    "        lane_counter = Counter(chunk[\"lane\"])\n",
    "        dominant_lane = max(chunk[\"lane\"], key=lane_counter.get)\n",
    "        trajectories.loc[chunk.index, \"dominantLane\"] = dominant_lane\n",
    "        if dominant_lane not in lanes:\n",
    "            continue\n",
    "        straight = car_goes_straight(lane_data, chunk)\n",
    "        if straight:\n",
    "            track_ids.append(track_id)\n",
    "    trajectories = trajectories[trajectories[\"trackId\"].isin(track_ids)]\n",
    "    # get times as which most cars stop at the intersection\n",
    "    redlight_peaks = intersection_peaks(trajectories, lane_data, lanes)\n",
    "    condition = (\n",
    "        (trajectories[\"time\"].isin(redlight_peaks))\n",
    "        & (trajectories[\"lane\"].isin(lanes))\n",
    "    )\n",
    "    stop_frames = np.sort(trajectories[condition][\"frame\"].unique())\n",
    "    frames_to_investigate = []\n",
    "    for begin, stop in zip(stop_frames[:-1], stop_frames[1:]):\n",
    "        # capture order every 10 seconds\n",
    "        ten_secs = 10 * fps\n",
    "        step_size = np.rint((stop - begin) / ten_secs)\n",
    "        ten_secs // step_size\n",
    "        frames_to_investigate.extend(list(np.arange(begin, stop, ten_secs)))\n",
    "    condition = (trajectories[\"frame\"].isin(frames_to_investigate))\n",
    "    redlight_situation = trajectories[condition]\n",
    "    # identifiy pairs of leader follower at stopping positions\n",
    "    pairs = pd.DataFrame()\n",
    "    leaders = []\n",
    "    for group_name, stopped_chunk in redlight_situation.groupby(by=[\"frame\", \"lane\"]):\n",
    "        sequence = stopped_chunk.sort_values(by=\"distanceIntersectionCrossing\", ascending=False)\n",
    "        sequence = sequence[~sequence[\"trackId\"].isin(leaders)]\n",
    "        # sequence = sequence[sequence[\"dominantLane\"]==group_name[1]]\n",
    "        sequence[\"follower\"] = np.roll(sequence[\"trackId\"].values, -1)\n",
    "        # sequence[\"order\"] = np.arange((len(sequence)))\n",
    "        sequence = sequence.iloc[:-1]\n",
    "        leaders.extend(list(sequence[\"trackId\"].values))\n",
    "        pairs = pd.concat((pairs, sequence))\n",
    "    situations = []\n",
    "    for index, row in pairs.iterrows():\n",
    "        situation = np.argmin(redlight_peaks - row[\"time\"])\n",
    "        situations.append(situation)\n",
    "    pairs.reset_index(inplace=True)\n",
    "    pairs[\"siutation\"] = situations\n",
    "    pairs = pairs.rename(columns={\"trackId\": \"leader\"})\n",
    "    # TODO:criterea\n",
    "    pairs = pairs[pairs[\"class\"].isin(classes)]\n",
    "    return pairs[[\"leader\", \"follower\"]].values\n",
    "    \n",
    "    \n",
    "        \n",
    "    \n",
    "def intersection_peaks(trajectories, lane_data, lanes=None):\n",
    "    # find peaks of when cars stop on lanes at the intersection\n",
    "    # downscale time\n",
    "    times = trajectories[\"time\"].unique()\n",
    "    times = np.sort(times)\n",
    "    downscale_number = 100\n",
    "    step_size = times.shape[0] // downscale_number\n",
    "    times = times[::step_size]\n",
    "\n",
    "    cars_stopped = np.zeros_like(times)\n",
    "    for idx, time in enumerate(times):\n",
    "        if lanes:\n",
    "            selected_lanes = lanes\n",
    "        else:\n",
    "            selected_lanes = np.unique(lane_data[\"trackId\"])\n",
    "        conditions = (\n",
    "            (trajectories[\"time\"]==time)\n",
    "            & (trajectories[\"speed\"]==0)\n",
    "            & (trajectories[\"lane\"].isin(selected_lanes))\n",
    "        )\n",
    "        selected_trajectories = trajectories[conditions]\n",
    "        cars_stopped[idx] = selected_trajectories[\"trackId\"].unique().shape[0]\n",
    "    time_step = np.mean(times[1:]-times[:-1])\n",
    "    time_dist = np.rint(30 / (time_step))\n",
    "    idxs = find_peaks(cars_stopped, distance=time_dist)[0]\n",
    "    return times[idxs]\n",
    "\n",
    "    \n",
    "selection = get_following_cars2(data, lane_data, meta_data, True, [1, 2])\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m identification \u001b[39min\u001b[39;00m selection:\n\u001b[0;32m      3\u001b[0m     identification \u001b[39m=\u001b[39m (identification[\u001b[39m0\u001b[39m], identification[\u001b[39m1\u001b[39m], \u001b[39m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     _estimate_parameters(identification, data, meta_data)\n",
      "Cell \u001b[1;32mIn[5], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[39mfor\u001b[39;00m identification \u001b[39min\u001b[39;00m selection:\n\u001b[0;32m      3\u001b[0m     identification \u001b[39m=\u001b[39m (identification[\u001b[39m0\u001b[39m], identification[\u001b[39m1\u001b[39m], \u001b[39m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m     _estimate_parameters(identification, data, meta_data)\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1457\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.SafeCallWrapper.__call__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:701\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1152\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:1135\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.trace_dispatch\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_pydevd_bundle/pydevd_cython.pyx:312\u001b[0m, in \u001b[0;36m_pydevd_bundle.pydevd_cython.PyDBFrame.do_wait_suspend\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\am3s12\\AppData\\Local\\miniconda3\\envs\\studienarbeit\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2070\u001b[0m, in \u001b[0;36mPyDB.do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, exception_type)\u001b[0m\n\u001b[0;32m   2067\u001b[0m             from_this_thread\u001b[39m.\u001b[39mappend(frame_custom_thread_id)\n\u001b[0;32m   2069\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_threads_suspended_single_notification\u001b[39m.\u001b[39mnotify_thread_suspended(thread_id, thread, stop_reason):\n\u001b[1;32m-> 2070\u001b[0m         keep_suspended \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_wait_suspend(thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\n\u001b[0;32m   2072\u001b[0m frames_list \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m   2074\u001b[0m \u001b[39mif\u001b[39;00m keep_suspended:\n\u001b[0;32m   2075\u001b[0m     \u001b[39m# This means that we should pause again after a set next statement.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\am3s12\\AppData\\Local\\miniconda3\\envs\\studienarbeit\\lib\\site-packages\\debugpy\\_vendored\\pydevd\\pydevd.py:2106\u001b[0m, in \u001b[0;36mPyDB._do_wait_suspend\u001b[1;34m(self, thread, frame, event, arg, suspend_type, from_this_thread, frames_tracker)\u001b[0m\n\u001b[0;32m   2103\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_call_input_hook()\n\u001b[0;32m   2105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocess_internal_commands()\n\u001b[1;32m-> 2106\u001b[0m     time\u001b[39m.\u001b[39;49msleep(\u001b[39m0.01\u001b[39;49m)\n\u001b[0;32m   2108\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcancel_async_evaluation(get_current_thread_id(thread), \u001b[39mstr\u001b[39m(\u001b[39mid\u001b[39m(frame)))\n\u001b[0;32m   2110\u001b[0m \u001b[39m# process any stepping instructions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "def _get_starting_time(pos_car):\n",
    "    starting_indexes = np.argwhere(pos_car[\"speed\"].values==0)\n",
    "    if starting_indexes.shape[0] != 0:\n",
    "        starting_index = np.clip(starting_indexes[-1,0] + 1, 0,\n",
    "                                 starting_indexes.shape[0]-1)\n",
    "    else:\n",
    "        starting_index = np.argmin(pos_car[\"speed\"]).astype(int)\n",
    "        # TODO: get starting index by min speed BEFORE intersection\n",
    "        # crossing\n",
    "        return pos_car[\"time\"].values[starting_index]\n",
    "    starting_time = pos_car[\"time\"].values[starting_index]\n",
    "    return starting_time\n",
    "\n",
    "def _estimate_parameters(identification: tuple,\n",
    "                              data_chunk: pd.DataFrame,\n",
    "                              meta_data: pd.DataFrame):\n",
    "    leader_chunk = data_chunk[data_chunk[\"trackId\"]==identification[0]]\n",
    "    follower_chunk = data_chunk[data_chunk[\"trackId\"]==identification[1]]\n",
    "    starting_time_l = _get_starting_time(leader_chunk)\n",
    "    leader_start = leader_chunk[leader_chunk[\"time\"]>starting_time_l]\n",
    "    leader_start.reset_index(drop=True, inplace=True)\n",
    "    # leader_time = leader_start[\"time\"].values\n",
    "    local_maxima_i = argrelextrema(\n",
    "        leader_start[\"acc\"].values, np.greater)[0]\n",
    "    # local_maxima = leader_time[local_maxima_i]\n",
    "    if local_maxima_i.shape[0] == 0:\n",
    "        taccmax_idx_l = np.argmax(leader_start[\"acc\"].values)\n",
    "    else:\n",
    "        taccmax_idx_l = local_maxima_i[0]\n",
    "    # leader_t_acc = leader_start[[\"time\", \"acc\"]].values[:taccmax_idx_l+1]\n",
    "    taccmax_l = leader_start[\"acc\"].values[taccmax_idx_l]\n",
    "    taccmax_l += 0.8 # see EIDM paper by Salles D.\n",
    "    # TODO: hardcoded speed limit 50km/h\n",
    "    speed_factor_leader =  leader_chunk[\"speed\"].max() / 13.8889\n",
    "    if isinstance(identification[1], str):\n",
    "        if identification == \"\":\n",
    "            return None, taccmax_l, None, None, speed_factor_leader, None\n",
    "    else:\n",
    "        if np.isnan(identification[1]) or identification[1] is None:\n",
    "            return None, taccmax_l, None, None, speed_factor_leader, None\n",
    "    pos_follower = follower_chunk[follower_chunk[\"time\"]==starting_time_l]\n",
    "    pos_leader = leader_chunk[leader_chunk[\"time\"]==starting_time_l]\n",
    "    leader_meta, follower_meta = _get_vehicle_meta_data(\n",
    "        meta_data, identification)\n",
    "    len_l, len_f = leader_meta[\"length\"], follower_meta[\"length\"]\n",
    "    # len_l, len_f = pos_leader[\"length\"].values[0], pos_follower[\"length\"].values[0]\n",
    "    pos_follower_xy = pos_follower[[\"xCenter\", \"yCenter\"]].values[0]\n",
    "    pos_leader_xy = pos_leader[[\"xCenter\", \"yCenter\"]].values[0]\n",
    "    min_gap = (np.sqrt(np.sum(np.square(pos_leader_xy-pos_follower_xy)))\n",
    "               - (len_l + len_f) / 2) + 0.1\n",
    "    starting_time_f = _get_starting_time(follower_chunk)\n",
    "    startup_delay = np.clip((starting_time_l - starting_time_f - 0.25),\n",
    "                            0, 2)\n",
    "    conditions = (\n",
    "        (follower_chunk[\"time\"].values<=starting_time_f)\n",
    "        & (np.isclose(follower_chunk[\"acc\"].values,0))\n",
    "    )\n",
    "    if not any(conditions):\n",
    "        # L134 F137\n",
    "        conditions = (\n",
    "            (follower_chunk[\"time\"].values<=starting_time_l)\n",
    "            & (np.isclose(follower_chunk[\"acc\"].values, 0, atol=0.1))\n",
    "        )\n",
    "        if not any(conditions):\n",
    "            conditions = np.zeros_like(follower_chunk[\"acc\"].values)\n",
    "            conditions[0] = 1\n",
    "            conditions = conditions.astype(bool)\n",
    "    starting_time_f = follower_chunk[conditions][\"time\"].values[-1]\n",
    "    follower_start = follower_chunk[\n",
    "        follower_chunk[\"time\"]>=starting_time_f]\n",
    "    speed_factor_follower =  follower_chunk[\"speed\"].max() / 13.8889\n",
    "    follower_start.reset_index(drop=True, inplace=True)\n",
    "    follower_time = follower_start[\"time\"].values\n",
    "    local_maxima_i = argrelextrema(\n",
    "        follower_start[\"acc\"].values, np.greater)[0]\n",
    "    # local_maxima = follower_time[local_maxima_i]\n",
    "    if local_maxima_i.shape[0] == 0:\n",
    "        taccmax_idx_f = np.argmax(follower_start[\"acc\"].values)\n",
    "    else:\n",
    "        taccmax_idx_f = next(\n",
    "            x for x in local_maxima_i if follower_start[\"acc\"].values[x] > 1)\n",
    "    taccmax_f = follower_start[\"acc\"].values[taccmax_idx_f]\n",
    "    # taccmax_f += 0.8 # see EIDM paper by Salles D. # not needed with the new\n",
    "    # files\n",
    "    taccmax_dur_f = follower_time[taccmax_idx_f] - follower_time[0]\n",
    "    follower_t_acc = follower_start[[\"time\", \"acc\"]].values[:taccmax_idx_f+1]\n",
    "    curve = _acceleration_curve_factory(taccmax_dur_f, starting_time_f)\n",
    "    solutions = ()\n",
    "    try:\n",
    "        solutions = op.curve_fit(\n",
    "            curve,\n",
    "            follower_t_acc[:,0],\n",
    "            follower_t_acc[:,1] / follower_t_acc[-1,1])\n",
    "    except RuntimeError:\n",
    "        # could not estimate parameters\n",
    "        pass\n",
    "    m_beg, m_flat = None, None\n",
    "    for solution in solutions:\n",
    "        if np.all(solution != np.inf):\n",
    "            m_beg, m_flat = solution\n",
    "            break\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure()\n",
    "    plt.plot(follower_t_acc[:,0], follower_t_acc[:,1] / follower_t_acc[-1,1])\n",
    "    plt.plot(follower_t_acc[:,0], curve(follower_t_acc[:,0], m_beg, m_flat))\n",
    "    plt.show()\n",
    "    params = (min_gap, taccmax_f, m_beg, m_flat, speed_factor_follower,\n",
    "              startup_delay)\n",
    "    return params\n",
    "for identification in selection:\n",
    "    identification = (identification[0], identification[1], 1)\n",
    "    _estimate_parameters(identification, data, meta_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "studienarbeit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98c8a1b4a8bc6f9ce164107038b03e5c28e09ff988705df94448fa2a2f71ebe2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
